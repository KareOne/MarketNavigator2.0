# Tracxn API Remote Worker Deployment
# Deploy this alongside the Tracxn API to connect to the main orchestrator

services:
  # ==========================================================================
  # Tracxn API Scraper
  # ==========================================================================
  tracxn_api:
    build: .
    container_name: remote-tracxn-api
    command: sh -c "python api.py"
    ports:
      - "8008:8008"
    volumes:
      - .:/app
    environment:
      PYTHONWARNINGS: "ignore::FutureWarning"
      # Status callbacks go to worker_agent which relays via WebSocket to orchestrator
      STATUS_CALLBACK_URL: http://worker_agent:9098
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8008/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  # ==========================================================================
  # Worker Agent (connects to main server orchestrator)
  # ==========================================================================
  worker_agent:
    build:
      context: ./worker_agent
      dockerfile: Dockerfile
    container_name: remote-tracxn-worker
    # No sleep needed - agent waits for local API to be ready before connecting
    command: python agent.py
    ports:
      - "9098:9098" # Status proxy port (internal use only)
    environment:
      - ORCHESTRATOR_URL=${ORCHESTRATOR_URL:-ws://89.42.199.54:8010/ws/worker}
      - WORKER_TOKEN=${WORKER_TOKEN}
      - API_TYPE=tracxn
      - WORKER_NAME=${WORKER_NAME:-tracxn-remote-1}
      - LOCAL_API_URL=http://tracxn_api:8008
      - HEARTBEAT_INTERVAL=10
      - RECONNECT_DELAY=5
      - LOG_LEVEL=INFO
    depends_on:
      - tracxn_api
    restart: unless-stopped

networks:
  default:
    name: tracxn-remote-network
